"""
CTGAN - Conditional Tabular GAN for Synthetic Patient Augmentation
Generates synthetic patient data to balance dataset and handle rare cases
"""

import pandas as pd
import numpy as np
from sdv.single_table import CTGANSynthesizer
from sdv.metadata import SingleTableMetadata
import config
import os

class PatientGAN:
    """
    Wrapper for CTGAN to generate synthetic hypertension patients
    """
    
    def __init__(self, epochs=300, batch_size=500):
        self.epochs = epochs
        self.batch_size = batch_size
        self.synthesizer = None
        self.metadata = None
        
    def prepare_metadata(self, data):
        """
        Prepare metadata for CTGAN to understand data types
        """
        print("\nüìã Preparing metadata for CTGAN...")
        
        # Create metadata object
        metadata = SingleTableMetadata()
        metadata.detect_from_dataframe(data)
        
        # Specify column types explicitly
        # Categorical columns
        categorical_cols = [
            'gender', 'diabetes', 'kidney_disease', 'smoker',
            'high_stress', 'sedentary_lifestyle', 'high_cholesterol',
            'hormonal_imbalance', 'pregnancy_postpartum', 
            'recommended_drug', 'age_group'
        ]
        
        for col in categorical_cols:
            if col in data.columns:
                metadata.update_column(
                    column_name=col,
                    sdtype='categorical'
                )
        
        # Numerical columns
        numerical_cols = [
            'age', 'systolic_bp', 'diastolic_bp', 'heart_rate',
            'bmi', 'duration_years', 'bp_reduction'
        ]
        
        for col in numerical_cols:
            if col in data.columns:
                metadata.update_column(
                    column_name=col,
                    sdtype='numerical'
                )
        
        self.metadata = metadata
        print("‚úÖ Metadata prepared")
        
        return metadata
    
    def train(self, data):
        """
        Train CTGAN on real patient data
        """
        print("\nüé® Training CTGAN for synthetic patient generation...")
        print(f"Training samples: {len(data)}")
        
        # Convert any category columns to object or int to avoid SDV error
        for col in data.columns:
            if data[col].dtype.name == 'category':
                # If it's numeric categories, convert to int
                try:
                    data[col] = data[col].astype(int)
                except:
                    # Otherwise convert to object
                    data[col] = data[col].astype(object)
        
        # Prepare metadata
        self.prepare_metadata(data)
        
        # Initialize CTGAN
        self.synthesizer = CTGANSynthesizer(
            metadata=self.metadata,
            epochs=self.epochs,
            batch_size=self.batch_size,
            verbose=True
        )
        
        # Train
        print("üîÑ Training in progress (this may take a few minutes)...")
        self.synthesizer.fit(data)
        
        print("‚úÖ CTGAN training complete!")
        
    def generate_synthetic_patients(self, n_samples, conditions=None):
        """
        Generate synthetic patients
        
        Args:
            n_samples: Number of synthetic patients to generate
            conditions: Optional dict of conditions (e.g., {'diabetes': 1})
        
        Returns:
            DataFrame of synthetic patients
        """
        if self.synthesizer is None:
            raise ValueError("CTGAN not trained yet! Call train() first.")
        
        print(f"\nüß¨ Generating {n_samples} synthetic patients...")
        
        if conditions:
            # Conditional generation
            synthetic_data = self.synthesizer.sample_from_conditions(
                conditions=conditions,
                num_rows=n_samples
            )
        else:
            # Unconditional generation
            synthetic_data = self.synthesizer.sample(num_rows=n_samples)
        
        print(f"‚úÖ Generated {len(synthetic_data)} synthetic patients")
        
        return synthetic_data
    
    def augment_minority_classes(self, data, target_column='recommended_drug', 
                                  balance_ratio=1.0):
        """
        Generate synthetic samples specifically for minority drug classes
        to balance the dataset
        
        Args:
            data: Original dataframe
            target_column: Column to balance
            balance_ratio: Target ratio (1.0 = fully balanced)
        
        Returns:
            Augmented dataframe
        """
        print("\n‚öñÔ∏è  Balancing dataset with synthetic minority samples...")
        
        # Get class distribution
        class_counts = data[target_column].value_counts()
        max_count = class_counts.max()
        
        print(f"Original distribution:")
        print(class_counts)
        
        # Calculate how many samples needed per class
        synthetic_samples = []
        
        for drug_class in class_counts.index:
            current_count = class_counts[drug_class]
            target_count = int(max_count * balance_ratio)
            samples_needed = max(0, target_count - current_count)
            
            if samples_needed > 0:
                print(f"  Generating {samples_needed} samples for {drug_class}...")
                
                # Generate synthetic samples for this class
                conditions = pd.DataFrame({target_column: [drug_class] * samples_needed})
                synthetic = self.generate_synthetic_patients(
                    n_samples=samples_needed,
                    conditions=conditions
                )
                synthetic_samples.append(synthetic)
        
        # Combine original and synthetic data
        if synthetic_samples:
            augmented_data = pd.concat([data] + synthetic_samples, ignore_index=True)
            print(f"\n‚úÖ Dataset augmented: {len(data)} ‚Üí {len(augmented_data)} samples")
            print(f"New distribution:")
            print(augmented_data[target_column].value_counts())
        else:
            augmented_data = data
            print("‚úÖ No augmentation needed, dataset already balanced")
        
        return augmented_data
    
    def save_model(self, filepath=None):
        """Save trained CTGAN model"""
        if filepath is None:
            filepath = os.path.join(config.MODELS_DIR, "ctgan_model.pkl")
        
        if self.synthesizer:
            self.synthesizer.save(filepath)
            print(f"üíæ CTGAN model saved to: {filepath}")
        else:
            print("‚ùå No model to save. Train first!")
    
    def load_model(self, filepath=None):
        """Load pre-trained CTGAN model"""
        if filepath is None:
            filepath = os.path.join(config.MODELS_DIR, "ctgan_model.pkl")
        
        if os.path.exists(filepath):
            self.synthesizer = CTGANSynthesizer.load(filepath)
            print(f"‚úÖ CTGAN model loaded from: {filepath}")
        else:
            print(f"‚ùå Model file not found: {filepath}")
    
    def evaluate_quality(self, real_data, synthetic_data):
        """
        Evaluate quality of synthetic data
        """
        print("\nüìä Evaluating synthetic data quality...")
        
        # Compare distributions
        print("\n1. Feature distributions comparison:")
        numerical_cols = real_data.select_dtypes(include=[np.number]).columns
        
        for col in numerical_cols[:5]:  # Show first 5 features
            real_mean = real_data[col].mean()
            synthetic_mean = synthetic_data[col].mean()
            real_std = real_data[col].std()
            synthetic_std = synthetic_data[col].std()
            
            print(f"  {col}:")
            print(f"    Real: Œº={real_mean:.2f}, œÉ={real_std:.2f}")
            print(f"    Synthetic: Œº={synthetic_mean:.2f}, œÉ={synthetic_std:.2f}")
        
        # Check for data leakage (synthetic samples too similar to real)
        print("\n2. Checking for potential data leakage...")
        # This is a simplified check - in production, use more sophisticated methods
        
        print("‚úÖ Quality evaluation complete")


# Quick test function
def test_gan():
    """Test CTGAN with sample data"""
    print("=" * 60)
    print("TESTING CTGAN MODULE")
    print("=" * 60)
    
    # Create sample data
    from data_loader import DataLoader
    loader = DataLoader()
    loader.create_synthetic_dataset_for_testing()
    data = loader.load_data()['synthetic']
    
    # Initialize and train GAN
    gan = PatientGAN(epochs=50, batch_size=500)  # Reduced epochs for testing
    gan.train(data)
    
    # Generate synthetic samples
    synthetic_data = gan.generate_synthetic_patients(n_samples=100)
    print("\nSynthetic data sample:")
    print(synthetic_data.head())
    
    # Evaluate quality
    gan.evaluate_quality(data, synthetic_data)
    
    # Test minority class augmentation
    augmented_data = gan.augment_minority_classes(data, balance_ratio=0.8)
    
    # Save model
    gan.save_model()
    
    print("\n‚úÖ GAN testing complete!")


if __name__ == "__main__":
    test_gan()
